{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-4. Linear_Regression_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_8T41-9zbSZ"
      },
      "source": [
        "# Multi-Variable Linear Regression Example with Pytorch Models (다중 변수의 선형회귀)\n",
        "- 국립한밭대학교 컴퓨터공학과 임경태\n",
        "- https://sites.google.com/view/aailab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lIpE4w9zZk1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mca1SNfEzZiX"
      },
      "source": [
        "x_train = np.array([[2, 3, 1], \n",
        "                    [4, 8, 9], \n",
        "                    [6, 2, 7], \n",
        "                    [8, 4, 6]])\n",
        "y_train = np.array([[3], \n",
        "                    [7], \n",
        "                    [5], \n",
        "                    [8]])\n",
        "\n",
        "n_samples = x_train.shape[0]\n",
        "n_features = x_train.shape[1]\n",
        "losses = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbTXHxpRzZfx"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEt9NHcPzZdL",
        "outputId": "b35e44d8-f1b9-4044-ec1b-a46bc78f8a8f"
      },
      "source": [
        "linear_model = torch.nn.Linear(in_features=3, out_features=1)       ## torch에서 제공하는 linear model 사용 (기존에는 직접 구현함)\n",
        "                                                                    ## Linear 함수 소스 직접 보기\n",
        "                                                                    ## in_features : 몇 개의 feature를 넣고 샆은지\n",
        "                                                                    ## out_features : 몇 개의 feature를 얻고 싶은지(output)\n",
        "                                                                    ## LQuiz... inear를 사용하지 않고 Fully_CoNnected Layer를 만들 때에는? linear 로 만들고 중간에 activation function을 넣어주면 FCN(ReLU)\n",
        "                                                                    ## W, b는 torch 형태로 되어 있음 backward 할 때 미분값을 바로 구할 수 있음\n",
        "                                                                    # instance가 출력됨 -> def forward가 실행됭\n",
        "\n",
        "print(linear_model)\n",
        "print(list(linear_model.parameters()))                              ## 첫 번째 tensor는 parmeter를 return 해서 보여줌"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=3, out_features=1, bias=True)\n",
            "[Parameter containing:\n",
            "tensor([[-0.1199,  0.1989,  0.4556]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4497], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QOMPQVNzZae",
        "outputId": "17e6fc55-9906-41d8-f35b-77206b6f54f1"
      },
      "source": [
        "x_train_torch = torch.from_numpy(x_train).float()\n",
        "y_train_torch = torch.from_numpy(y_train).float()\n",
        "print(x_train_torch)\n",
        "print(x_train_torch.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 3., 1.],\n",
            "        [4., 8., 9.],\n",
            "        [6., 2., 7.],\n",
            "        [8., 4., 6.]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlKg4h-jzZX_"
      },
      "source": [
        "predicted_y = linear_model(x_train_torch)                       ## 예) 수학, 과학, 영어 점수 넣어서 return 값을 predicted_y에 저장함\n",
        "## predicted_y = linear_model.forward(x_train_torch)            ## linear model을 설계하고 f 함수를 forward"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kt525ZDzZVl"
      },
      "source": [
        "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01) \n",
        "loss_function = torch.nn.MSELoss()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHniQjJmzZSu",
        "outputId": "ccba91b7-5d79-4d96-9e3c-e44de8f3038f"
      },
      "source": [
        "linear_model.train()                                            ## linear_model.train() : 모델이 커질수록 관리할 수 없으니 내장함수인 train을 이용해서 linear 에 들어간 w,b는 업데이트 하는걸로 설정을 바꿔줌\n",
        "for idx in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  predicted_y = linear_model(x_train_torch)\n",
        "  loss = loss_function(predicted_y, y_train_torch)  \n",
        "  print(loss.item())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.113842010498047\n",
            "5.4332146644592285\n",
            "3.791672706604004\n",
            "2.7691736221313477\n",
            "2.1179513931274414\n",
            "1.6914077997207642\n",
            "1.4024457931518555\n",
            "1.1990389823913574\n",
            "1.049888014793396\n",
            "0.9359879493713379\n",
            "0.8456623554229736\n",
            "0.7716289162635803\n",
            "0.7092626094818115\n",
            "0.655558168888092\n",
            "0.6085152626037598\n",
            "0.5667595863342285\n",
            "0.5293225646018982\n",
            "0.495496928691864\n",
            "0.4647504985332489\n",
            "0.4366716146469116\n",
            "0.41093480587005615\n",
            "0.3872746229171753\n",
            "0.36547189950942993\n",
            "0.3453405797481537\n",
            "0.32672327756881714\n",
            "0.30948305130004883\n",
            "0.29349982738494873\n",
            "0.27866822481155396\n",
            "0.26489391922950745\n",
            "0.25209271907806396\n",
            "0.24018898606300354\n",
            "0.22911369800567627\n",
            "0.21880480647087097\n",
            "0.2092050313949585\n",
            "0.2002623975276947\n",
            "0.19192931056022644\n",
            "0.18416164815425873\n",
            "0.1769188940525055\n",
            "0.17016291618347168\n",
            "0.1638604998588562\n",
            "0.15797892212867737\n",
            "0.1524885892868042\n",
            "0.14736220240592957\n",
            "0.14257416129112244\n",
            "0.1381012201309204\n",
            "0.1339210867881775\n",
            "0.13001340627670288\n",
            "0.12635931372642517\n",
            "0.1229415237903595\n",
            "0.11974315345287323\n",
            "0.11674924194812775\n",
            "0.11394570767879486\n",
            "0.11131946742534637\n",
            "0.10885787010192871\n",
            "0.10655002295970917\n",
            "0.10438521206378937\n",
            "0.10235334932804108\n",
            "0.10044556856155396\n",
            "0.0986531525850296\n",
            "0.09696817398071289\n",
            "0.09538331627845764\n",
            "0.09389178454875946\n",
            "0.09248688817024231\n",
            "0.09116266667842865\n",
            "0.08991396427154541\n",
            "0.08873540908098221\n",
            "0.08762217313051224\n",
            "0.08656969666481018\n",
            "0.08557403087615967\n",
            "0.08463113009929657\n",
            "0.08373749256134033\n",
            "0.08288967609405518\n",
            "0.08208461850881577\n",
            "0.08131930977106094\n",
            "0.0805910974740982\n",
            "0.07989773154258728\n",
            "0.07923649996519089\n",
            "0.07860524952411652\n",
            "0.07800222933292389\n",
            "0.07742524892091751\n",
            "0.07687274366617203\n",
            "0.07634294033050537\n",
            "0.0758342444896698\n",
            "0.07534560561180115\n",
            "0.0748753547668457\n",
            "0.07442224025726318\n",
            "0.07398553192615509\n",
            "0.07356362044811249\n",
            "0.07315577566623688\n",
            "0.07276112586259842\n",
            "0.07237870991230011\n",
            "0.07200796157121658\n",
            "0.07164765894412994\n",
            "0.07129748910665512\n",
            "0.0709565132856369\n",
            "0.07062473148107529\n",
            "0.07030083984136581\n",
            "0.06998477131128311\n",
            "0.06967590749263763\n",
            "0.06937380880117416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_dk1BR6agB"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}